{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection in Lymphoma Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore a dataset that describes the medical condition of Lymphoma patients!\n",
    "We will also implement some anomaly detection algorithms as we do not have domain knowledge in this field.\n",
    "\n",
    "There are three different kinds of outliers:\n",
    "1. Global outliers:\n",
    "A data point is considered a global outlier if its value is far outside the entirety of the data set in which it is found.\n",
    "2. Contextual outliers:\n",
    "A data point is considered a contextual outlier if its value significantly deviates from the rest the data points in the same context.\n",
    "3. Collective outliers:\n",
    "A subset of data points within a data set is considered anomalous if those values as a collection deviate significantly from the entire data set, but the values of the individual data points are not themselves anomalous in either a contextual or global sense.\n",
    "\n",
    "We will focus our project on global outliers since we do not fundementally understand the context of the data and we don't have enough data to inspect any collective anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Diffuse large B-cell lymphoma (DLBCL) is an aggressive type of non-Hodgkin lymphoma that develops from the B-cells in the lymphatic system. Under the microscope, large malignant lymphocytes are seen diffusely throughout the specimen. <br/>\n",
    "Often the first symptom of DLBCL is a painless swelling in the neck, armpit or groin that is caused by enlarged lymph nodes. These lumps can grow quite quickly, often over a period of a few weeks.  Sometimes, other parts of the body are also affected. This is known as ‘extranodal’ disease because it is happening outside of the lymph nodes, and includes the stomach or bowel being affected, which may cause abdominal discomfort or pain, diarrhoea or bleeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Goal \n",
    "To get rid of outliers in the most effecient way so we can build the optimal classifer whether the patient has extranodal sites or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/linb/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB\n",
      "    conda-4.10.3               |   py38hecd8cb5_0         2.9 MB\n",
      "    libxgboost-1.3.3           |       h23ab428_0         1.2 MB\n",
      "    py-xgboost-1.3.3           |   py38hecd8cb5_0         136 KB\n",
      "    xgboost-1.3.3              |   py38hecd8cb5_0          23 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         pkgs/main/osx-64::libxgboost-1.3.3-h23ab428_0\n",
      "  py-xgboost         pkgs/main/osx-64::py-xgboost-1.3.3-py38hecd8cb5_0\n",
      "  xgboost            pkgs/main/osx-64::xgboost-1.3.3-py38hecd8cb5_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.0-py38hecd8cb5_0 --> 4.10.3-py38hecd8cb5_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "#!pip install missingno\n",
    "#!pip install pandas_profiling\n",
    "#!pip install rfpimp\n",
    "#!pip install pimp\n",
    "!conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linb/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['dlopen(/Users/linb/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/linb/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff17c96fd684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrfpimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataIter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mlibname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         raise XGBoostError(\n\u001b[0m\u001b[1;32m    182\u001b[0m             f\"\"\"\n\u001b[1;32m    183\u001b[0m \u001b[0mXGBoost\u001b[0m \u001b[0mLibrary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlibname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['dlopen(/Users/linb/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/linb/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "import rfpimp\n",
    "import missingno as msno\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prognostics_dev.csv', skiprows=range(517,521))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Treatment__\": \"Treatment\", \"Status at Follow_up_ 0 Alive_ 1 Dead\": \"Follow up Status Alive=0 Dead=1\", \"Follow_up Time _yrs\": \"Follow up Time (yrs)\", \"Progression_Free Survival _PFS_ Status_ 0 No Progressoin_ 1 Progression\": \"PFS Status No Progress=0 Progress=1\", \"Progression_Free Survival _PFS_ Time _yrs\": \"PFS (yrs)\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 520 observations and 21 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have noticed that on the last 4 rows there is  some explanation about the values in the data that will later on may be helpful: <br/>\n",
    "NA: not available <br/>\n",
    "IPI range groups: 0-1 (low); 2-3 (intermediate); 4-5 (high).  If some IPI components are missing and the range of the IPI would fall between these groups, this parameter is left blank and the case was not used for the IPI analysis. <br/>\n",
    "Chemoimmunotherapy: CHOP or CHOP-like chemotherapy plus Rituximab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Desciption <br/>\n",
    "\n",
    "After asking a MD to calrify the meaning of the features we came up with this:  <br/>\n",
    "dbGaP submitted subject ID - .... <br/>\n",
    "dbGaP accession - An accession number in bioinformatics is a unique identifier given to a DNA or protein sequence record to allow for tracking of different versions of that sequence record and the associated sequence over time in a single data repository. <br/>\n",
    "Diagnosis - The specific type of cancer <br/>\n",
    "Gene Expression Subgroup - A subtype of lymphoma, any subtype that is each affected differently by chemotherapy.\n",
    "Genetic Subtype - The gene that the mutation he makes cause Lymphoma.\n",
    "Biopsy Type  If value is \"pre-treatment\" that means biopsy speciman was taken before the patient's treatment. If the value is \"relapsed\" that means the speciman was taken after the patient already had Lymphoma. <br/>\n",
    "Treatment - The kind of treatment that was given to the patient  <br/>\n",
    "Gender - The patient's gender  <br/>\n",
    "Age - The patient's age in years  <br/>\n",
    "Ann Arbor Stage - A unique lymphoma staging classification system from 1 to 4  <br/>\n",
    "LDH ratio - The level of lactate dehydrogenase (LDH) in the blood  <br/>\n",
    "ECOG Performance Status - Describes a patient’s level of functioning in terms of their ability to care for themself from 0 to 5  <br/>\n",
    "Number of Extranodal Sites - The number of a nodal cancer metastasis beyond the confines of the capsule of a lymph node into adjacent tissues.  <br/>\n",
    "IPI Group - A categorical presentation of IPI range.\n",
    "0-1 (low); 2-3 (intermediate); 4-5 (high). If some IPI components are missing and the range of the IPI would fall between these groups, this parameter is left blank and the case was not used for the IPI analysis. <br/>\n",
    "IPI Range - clinical tool developed by oncologists to aid in predicting the prognosis of patients with aggressive non-Hodgkin's lymphoma from 0 to 5  <br/>\n",
    "Follow up Status Alive=0 Dead=1 - Wheather the person was alive or not in the follow up. <br/>\n",
    "Follow up Time (years) - Is measured from time zero (the start of the study or from the point at which the participant is considered to be at risk) until the study ends or the participant is lost.  <br/>\n",
    "PFS status - Wheather the person showed progress since the treatment was given.  <br/>\n",
    "PFS time (years) - the length of time during and after the treatment of a disease that a patient lives with the disease but it does not get worse.  <br/>\n",
    "Included in survival analysis - Wheather the person was included in the survival analysis.  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable_report = ProfileReport(df=df,progress_bar=False,samples=None, missing_diagrams=None, duplicates=None, interactions=None)\n",
    "# We calculated correlations & missing diagrams by ourselves (below) to show programming abilities & generate good-looking visualizations :)\n",
    "### Getting information about the data, such as: type, unique values, missing values, quantile statistics, mean, mode, median, standard deviation, sum, skewness, frequent values, histograms, correlation between variables, count etc.\n",
    "\n",
    "#variable_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualization of numeric features\n",
    "df.hist(figsize=(30,30), bins=30, color='darkred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.groupby('Diagnosis').size().plot(kind='pie', autopct='%.2f')\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Diagnosis Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that all of the patients have the same diagnosis, so we can get rid of this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.groupby('Gender').size().plot(kind='pie', autopct='%.2f')\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Gender Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.groupby('Gene Expression Subgroup').size().plot(kind='pie', autopct='%.2f')\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Gene Expression Subgroup Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Treatment\", y=\"Age\", hue=\"Gender\", kind=\"swarm\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Gender\", y=\"PFS (yrs)\", hue=None, data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"Follow up Time (yrs)\", x=\"Number of Extranodal Sites\", palette=[\"m\", \"g\"],\n",
    "            data=df)\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Included in Survival Analysis\", y=\"Age\", hue=None, data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=df,\n",
    "    x=\"ECOG Performance Status\", y=\"LDH Ratio\", hue=\"Gender\",\n",
    "    height=5)\n",
    "\n",
    "# Use more informative axis labels than are provided by default\n",
    "g.set_axis_labels(\"ECOG Preformance Status\", \"LDH Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( df[\"Ann Arbor Stage\"],df[\"Number of Extranodal Sites\"], \"o\")\n",
    "plt.ylabel(\"Number of Extranodal Sites\")\n",
    "plt.xlabel(\"Ann Arbor Stage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('IPI Group')[['IPI Range']].agg(['mean', 'min', 'max','unique'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack as sparse_hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "class Initial_pre_processing_Transformer(TransformerMixin):\n",
    "    '''\n",
    "    Imputes the numeric_fill_na_with_zeros columns with 0, creates a new column of the total number of guests, \n",
    "    Transforms the category_cols into one hot encoder\n",
    "    '''\n",
    "#     X_cols = []\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        '''\n",
    "        Learn a vocabulary dictionary of all tokens in the the category_cols.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        self\n",
    "        '''   \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms num_cat columns to a sparse matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Sparse Matrix\n",
    "            Matrix consisting of the numeric columns, the numeric_fill_na after imputation with 0, num_of_guest collumn and OHE columns\n",
    "        '''   \n",
    "        X_copy = X.copy()\n",
    "        X_copy.drop(X_copy.columns[[0, 1, 3]], axis=1, inplace = True) #dropping the diagnosis (the same for all) and other two feature that might predict what we're trying to predict \n",
    "        X_copy['Gender'] = X_copy['Gender'].map({'M': 0,'F': 1})\n",
    "        X_copy['Included in Survival Analysis'] = X_copy['Included in Survival Analysis'].map({'Yes': 1,'No': 0})\n",
    "        X_copy.replace(\"Pre-treatment\", \"Pretreatment\",inplace=True)\n",
    "        X_copy['binary_num_of_nodes'] = X_copy['Number of Extranodal Sites'].copy()\n",
    "                \n",
    "        # Change only the not-null values\n",
    "        not_null_node_indices = X_copy[~X_copy['Number of Extranodal Sites'].isna()].index\n",
    "        X_copy.loc[not_null_node_indices,'binary_num_of_nodes'] = np.where(X_copy.loc[not_null_node_indices,:]['Number of Extranodal Sites']>0, 1, 0)\n",
    "\n",
    "        return X_copy.drop(['binary_num_of_nodes','Number of Extranodal Sites'], axis =1) , X_copy['binary_num_of_nodes']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial_pre_processing_Transformer = Initial_pre_processing_Transformer()\n",
    "df_after_preprocessing, y = Initial_pre_processing_Transformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_color = (0, 0.4, 0.6)\n",
    "msno.matrix(df_after_preprocessing,color=missing_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(TransformerMixin):\n",
    "    def __init__(self,  is_numeric_Transformer=True, is_cat_Transformer=True, is_ipi_values_Transformer=True\n",
    "                ):\n",
    "        '''\n",
    "        Consists of 5 transformers: 1) time_until_order_transformer, 2) num_cat_Transformer, 3) deposit_OHE, 4) country_OHE, 5) anon_Transformer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        1) is_time_until_order_transformer - True if we want to enable the time_until_order_transformer, Otherwise False\n",
    "        2) is_num_cat_Transformer - True if we want to enable the num_cat_Transformer, Otherwise False\n",
    "        3) is_deposit_OHE - True if we want to enable the deposit_OHE, Otherwise False\n",
    "        4) is_country_OHE - True if we want to enable the country_OHE, Otherwise False\n",
    "        5) is_anon_Transformer - True if we want to enable the anon_Transformer, Otherwise False\n",
    "        '''\n",
    "        feature_for_transformer =[]\n",
    "\n",
    "        if is_numeric_Transformer:\n",
    "            feature_for_transformer.append(('num',numeric_Transformer()))    \n",
    "            \n",
    "        if is_cat_Transformer:\n",
    "            feature_for_transformer.append(('',cat_Transformer()))\n",
    "        \n",
    "        if is_ipi_values_Transformer:\n",
    "            feature_for_transformer.append(('ipi_values',ipi_values_Transformer()))\n",
    "        \n",
    "        self.transformer = FeatureUnion(feature_for_transformer)\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        '''\n",
    "        Run each of the activated transformers' fit functions\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Self \n",
    "        '''\n",
    "        return self.transformer.fit(X)\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Run each of the activated transformers' transform functions\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        DataFrame\n",
    "            DataFrame with all of the transformed columns\n",
    "        '''        \n",
    "        return self.transformer.transform(X).astype(float)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        '''\n",
    "        Run each of the activated transformers' get_feature_names functions\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        List\n",
    "            A list of feature names\n",
    "        '''   \n",
    "        return self.transformer.get_feature_names()\n",
    "\n",
    "#***************************************************************************************\n",
    "class numeric_Transformer(TransformerMixin):\n",
    "    numeric_features = ['Ann Arbor Stage','LDH Ratio','ECOG Performance Status','Gender','Age',\n",
    "                       'Follow up Status Alive=0 Dead=1', 'Follow up Time (yrs)',\n",
    "       'PFS Status No Progress=0 Progress=1', 'PFS (yrs)',\n",
    "       'Included in Survival Analysis']\n",
    "\n",
    "    num_of_numeric_features = len(numeric_features)\n",
    "    def __init__(self,num_medians=np.zeros(num_of_numeric_features), **cv_kwargs):\n",
    "        self.num_medians = num_medians\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Learn the median values of the anon columns\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        self\n",
    "        ''' \n",
    "        self.num_medians = X[self.numeric_features].median()\n",
    "#         print(self.num_medians)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        Transforms all anon features to a sparse matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Sparse Matrix\n",
    "            Matrix consisting of all anon features after imputation with median values\n",
    "        '''   \n",
    "        X_copy = X.copy()        \n",
    "\n",
    "        # Calculate median of every anon feature (separately) and impute with median\n",
    "\n",
    "        X_num = csr_matrix(X_copy[self.numeric_features].fillna(self.num_medians).apply(pd.to_numeric,errors='coerce').values.astype(float))\n",
    "        return sparse_hstack([X_num])\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        '''\n",
    "        returns a list of feature names consisting of each of the anon_features.\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        List\n",
    "            A list of feature names\n",
    "        '''   \n",
    "        return [x.lower() for x in self.numeric_features]    \n",
    "    \n",
    "#***************************************************************************************\n",
    "\n",
    "class cat_Transformer(TransformerMixin):\n",
    "    '''\n",
    "    Imputes the numeric_fill_na_with_zeros columns with 0, creates a new column of the total number of guests, \n",
    "    Transforms the category_cols into OHE\n",
    "    '''    \n",
    "    category_cols = ['Gene Expression Subgroup','Biopsy Type','Treatment', 'Genetic Subtype']\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        '''\n",
    "        Learn a vocabulary dictionary of all tokens in the the category_cols.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        self\n",
    "        '''   \n",
    "        category_col_ohe_names = [col.lower() for col in self.category_cols]\n",
    "        category_col_ohe = [OHEcol(col) for col in self.category_cols]\n",
    "        self.category_feature_union = FeatureUnion([(category_col_ohe_names[i], category_col_ohe[i]) for i, _ in enumerate(category_col_ohe_names)])\n",
    "        self.category_feature_union.fit(X[self.category_cols])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms num_cat columns to a sparse matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Sparse Matrix\n",
    "            Matrix consisting of the numeric columns, the numeric_fill_na after imputation with 0, num_of_guest collumn and OHE columns\n",
    "        '''   \n",
    "        X_copy = X.copy()        \n",
    "        X_one_hot_category = self.category_feature_union.transform(X[self.category_cols].fillna(''))\n",
    "        return sparse_hstack([X_one_hot_category])\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        '''\n",
    "        returns a list of feature names consisting of each of the num_cat cols.\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        List\n",
    "            A list of feature names\n",
    "        '''   \n",
    "\n",
    "        X_one_hot_category = self.category_feature_union.get_feature_names()\n",
    "        return X_one_hot_category\n",
    "    \n",
    "class OHEcol(TransformerMixin):\n",
    "    def __init__(self,col):\n",
    "        self.col = col\n",
    "        self.cv = CountVectorizer(min_df=0.05)\n",
    "        return\n",
    "    \n",
    "    def _prepare(self,X):\n",
    "        '''\n",
    "        Imputes missing values with 'unknown'\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Series\n",
    "            Returns the column after imputation with 'unknown'\n",
    "        '''  \n",
    "        return X[self.col].fillna('Unknown')  \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Learn a vocabulary dictionary of all tokens in the OHE col.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        self\n",
    "        ''' \n",
    "        self.cv.fit(self._prepare(X).astype(str))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        Creates a OHE of the column using CountVectorizer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Sparse Matrix\n",
    "            Matrix consisting a OHE for the column values that appeared in at lease 0.001 of the data (min_df=0.001)\n",
    "        '''   \n",
    "        return self.cv.transform(self._prepare(X).astype(str))\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        '''\n",
    "        returns a list of feature names consisting of each of the OHE cols.\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        List\n",
    "            A list of feature names\n",
    "        '''   \n",
    "        return [cv_f for cv_f in self.cv.get_feature_names()]\n",
    "\n",
    "#***************************************************************************************\n",
    "\n",
    "class ipi_values_Transformer(TransformerMixin):\n",
    "    \n",
    "#     relevant_cols = ['IPI Group','IPI Range']\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Learn the median values of the relevant_col\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        self\n",
    "        ''' \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        Transforms fixed relevant_col to a sparse matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        Sparse Matrix\n",
    "            Matrix consisting of the numeric columns, the numeric_fill_na after imputation with 0, num_of_guest collumn and OHE columns\n",
    "        '''   \n",
    "        \n",
    "        def impute_ipi(row):\n",
    "            ipi_group = row['IPI Group']\n",
    "            ipi_range = row['IPI Range']\n",
    "            if pd.isna(ipi_group):                \n",
    "                \n",
    "                # calculate mean from ipi_range \n",
    "                if ipi_range>5:\n",
    "                    digits = [int(d) for d in str(ipi_range)]\n",
    "                    ipi_range =  sum(digits)/len(digits)\n",
    "                \n",
    "                if 0<=ipi_range<2:\n",
    "                    return 1  # 'Low'\n",
    "                elif 2<=ipi_range<4:\n",
    "                    return 2  # 'Intermediate'\n",
    "                else:\n",
    "                    return 3  # 'High'\n",
    "            else:\n",
    "                if ipi_group =='Low':\n",
    "                    return 1 # 'Low'\n",
    "                elif ipi_group =='Intermediate':\n",
    "                    return 2 # 'Intermediate'\n",
    "                else:\n",
    "                    return 3\n",
    "                    \n",
    "        def get_mean_ipi(number):\n",
    "            if number>5:\n",
    "                digits = [int(d) for d in str(number)]\n",
    "                return sum(digits)/len(digits)\n",
    "            else:\n",
    "                return number\n",
    "\n",
    "        def get_min_ipi(number):\n",
    "            if number>5:\n",
    "                digits = [int(d) for d in str(number)]\n",
    "                return min(digits)\n",
    "            else:\n",
    "                return number\n",
    "\n",
    "        def get_max_ipi(number):\n",
    "            if number>5:\n",
    "                digits = [int(d) for d in str(number)]\n",
    "                return max(digits)\n",
    "            else:\n",
    "                return number    \n",
    "            \n",
    "#         X_mean = csr_matrix(self._impute(X).apply(lambda row: get_mean_ipi(row)).values)\n",
    "        X_mean = csr_matrix(X['IPI Range'].apply(lambda row: get_mean_ipi(row)).values).T\n",
    "        X_min = csr_matrix(X['IPI Range'].apply(lambda row: get_min_ipi(row)).values).T\n",
    "        X_max = csr_matrix(X['IPI Range'].apply(lambda row: get_max_ipi(row)).values).T\n",
    "        ipi_group = csr_matrix(X[['IPI Group','IPI Range']].apply(lambda row: impute_ipi(row), axis = 1).values).T\n",
    "        return sparse_hstack([X_mean,X_min,X_max,ipi_group])\n",
    "\n",
    "   \n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        '''\n",
    "        returns the relevant_col name.\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        Returns\n",
    "        ----------\n",
    "        String\n",
    "            relevant_col\n",
    "        '''   \n",
    "        return ['mean','min','max','ipi_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "feature_transformer = FeatureTransformer()\n",
    "x_train_transformed = pd.DataFrame(feature_transformer.fit_transform(df_after_preprocessing).A,index=df_after_preprocessing.index,columns=feature_transformer.get_feature_names())\n",
    "# x_test = pd.DataFrame(feature_transformer.transform(df_after_preprocessing).A,index=df_after_preprocessing.index,columns=feature_transformer.get_feature_names())\n",
    "x_train_transformed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_color = (0, 0.4, 0.6)\n",
    "msno.matrix(x_train_transformed,color=missing_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary_isunlabeled = np.array(y.isna().tolist())\n",
    "y_unlabeled = y[y_binary_isunlabeled]\n",
    "X_unlabled = x_train_transformed[y_binary_isunlabeled]\n",
    "y_labeled = y[~y_binary_isunlabeled]\n",
    "X_labeled = x_train_transformed[~y_binary_isunlabeled]\n",
    "\n",
    "X_train_labeled, X_test_labeled, y_train_labeled, y_test_labeled = train_test_split(X_labeled, y_labeled, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(data, numeric_features):\n",
    "    \n",
    "    cor_mat = data[numeric_features].corr()\n",
    "    corr_left_triangle = cor_mat.where(np.tril(np.ones(cor_mat.shape)).astype(np.bool))\n",
    "    # Generate a mask for the upper triangle\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(12, 12))\n",
    "    # Generate a custom diverging colormap\n",
    "    ax.set_facecolor('xkcd:white')\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    sns.heatmap(corr_left_triangle, cmap=cmap, vmax=1, center=0,  # vmax=max_correlation\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_correlation_matrix(x_train_transformed,x_train_transformed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features we consider to drop: <br/>\n",
    "-ipi values min&max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imp = rfpimp.cv_importances(X_train = X_train_labeled, y_train = y_train_labeled, k=3, model=XGBClassifier(n_jobs=-1))\n",
    "perm_imp_df = perm_imp.reset_index().copy()\n",
    "perm_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=\"Importance\",y=\"Feature\",data=perm_imp_df[perm_imp_df.Importance>0.0005])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestImportance = RandomForestClassifier(n_estimators=100)\n",
    "forestImportance.fit(X_train_labeled, y_train_labeled.values.ravel())\n",
    "feature_importance = forestImportance.feature_importances_  \n",
    "\n",
    "forest_importance_df = pd.DataFrame(list(zip(X_train_labeled.columns, feature_importance / feature_importance.max())), columns=['feature', 'relative_importance']).sort_values('relative_importance', ascending=False)\n",
    "\n",
    "top_i = 40 # Choose how many features we want to plot\n",
    "# Features in red are the random features we've created for comparison during feature importance\n",
    "clrs = ['red' if ('random' in x) else 'gray' for x in forest_importance_df.feature]\n",
    "sns.barplot(data=forest_importance_df.iloc[0:top_i,:],x=\"relative_importance\", y=\"feature\",palette=clrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examined two feature selection models, we decided to continue with the first model as it is showing us the score gain for every feature compared to a random values feature.\n",
    "In addition, random forest classiefier gives priority to numeric continuous features as there are more threasholds to give them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
